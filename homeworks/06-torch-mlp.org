Training neural networks using torch

The goal is to implement a stochastic gradient descent algorithm for
training a linear model and a neural network. Previously we
implemented the full gradient learning algorithm for linear model from
scratch using numpy. This week we will use the torch module in python,
which provides automatic differentiation (you don't have to code the
gradients yourself, which helps a lot for the complex gradients in
neural networks). You should implement three different classes.

** Class: TorchModel

- This class implements a predictive model using the torch framework.
- similar to https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html#creating-models
- Inherits from torch.nn.Module.
- Defines an __init__ method which inputs units_per_layer (list of
  integers).
- Defines forward method which takes an input matrix (nrow=number of
  observations, ncol=number of features) and returns a vector with the
  outputs/predicted scores from the neural network.

** Class: TorchLearner

This class implements fit/predict methods for weight matrix parameter
learning and making predictions with the previous class. It should be
similar to what we did last week, except that you should use torch
instead of your own implementation of gradients.

- __init__ method should store hyper-parameters, max_epochs,
  batch_size, step_size, and units_per_layer (list or numpy array of
  positive integers, first element should equal number of input
  features, last element should be 1). Also instantiate a
  TorchModel() and save as an attribute of this instance,
  self.model. Also instantiate torch.optim.SGD and save as
  self.optimizer, and instantiate torch.nn.BCEWithLogitsLoss and save
  as self.loss_fun.
- take_step(X=batch_features, y=batch_labels) method should
  - begin by computing self.model(X) and saving as vector of
    predictions for this batch.
  - Use self.loss_fun to compute the mean loss.
  - Use optimizer.zero_grad, loss.backward, optimizer.step to compute
    gradients and take a step as in
    https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html#optimizing-the-model-parameters
- fit(X=subtrain_features, y=subtrain_labels) method should run
  gradient descent until max_epochs is reached. There should be two
  for loops, first over epochs, then over batches. You should use the
  take_step method on each batch. Compute and store the
  subtrain/validation loss at the end of each epoch.
- decision_function(X=test_features) method should return a numpy
  array of real number predicted scores given the current weights in
  the neural network.
- predict(X=test_features) method should return a numpy array of
  predicted classes given the current weights in the neural network.

** Class: TorchLearnerCV

This class should implement hyper-parameter learning (select the
number of epochs which minimizes loss on validation set). Like the CV
class last week, this should have a fit method that splits train into
subtrain and validation sets, then runs gradient descent and computes
loss with respect to both sets at the end of each epoch.  After
learning the best number of epochs using the validation set, you
should re-run gradient descent on the entire train set using that
number of epochs.

** Hyper-parameter training and diagnostic plot

You should compute the subtrain/validation loss at the end of each
epoch.
- You should use two different models (each with a different value of
  units_per_layer), first with a linear model (no hidden layers), and
  second with a "deep" neural network (with at least two hidden
  layers).
- Run it on the full spam/zip data sets, and make a plot for each data
  set and model, of subtrain/validation loss as a function of number
  of epochs. For full credit your subtrain loss should always
  decrease, and your validation loss should show the expected U shape
  (if it does not, then you may need to change hyper-parameters). In
  each plot, what is the best number of epochs?

** Experiments/application

- Use similar experimental setup as previous homeworks (with 3-fold CV
  train/test splits defined by KFold, and with featureless,
  GridSearchCV+KNeighborsClassifier and LogisticRegressionCV), but add
  your two new algorithms to compare (TorchLinear for linear model,
  and TorchDeep for neural network with at least two hidden layers).
- Run experiments on both spam and zip data.
- Make sure to scale the spam data before putting them into the
  data_dict and before any splitting (so you don't have to worry about
  scaling in neural network code).
- Show a table of resulting test accuracy numbers, as well as a ggplot
  like in last homework. 
- Does your implementation get similar test accuracy as scikit-learn,
  or better?  (it should!)

** Extra credit

- Show your linear model from last week on your test accuracy plot. Is
  it more accurate than the torch linear model, or about the same?
  (they should be about the same if everything was implemented
  correctly)
- Implement learning an intercept for every hidden/output unit, as an
  instantiation parameter in TorchModel(intercept=True). Hint: you just
  need to use bias=True or False when instantiating the
  torch.nn.Linear class. Show both intercept=True and False on your
  test accuracy plot: which is more accurate, or are they about the
  same? (it should be about the same, maybe a little more accurate
  with intercept)

** FAQ

- How to make sure hyper-parameters are correctly chosen? You need to
  experiment with hyper-parameters until you find some combination
  (max_epochs, batch_size, step_size, units_per_layer) which results
  in the characteristic loss curves (subtrain mostly always
  decreasing, validation U shaped as number of epochs increases).
