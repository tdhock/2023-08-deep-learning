---
title: "Other"
author: "Toby Dylan Hocking"
output: 
  beamer_presentation:
    dev: png
    includes:
      in_header: "04-header.tex"	
---

```{r opts, echo=FALSE}
knitr::opts_chunk$set(
  echo=FALSE, results=FALSE,
  dpi=200,
  fig.width=10,
  fig.height=6)
Sys.setenv(RETICULATE_PYTHON=if(.Platform$OS.type=="unix")
  "/home/tdhock/.local/share/r-miniconda/envs/cs570s22/bin/python"
  else "~/Miniconda3/envs/cs570s22/python.exe")
reticulate::use_condaenv("cs570s22", required=TRUE)
in_render <- !is.null(knitr::opts_knit$get('rmarkdown.pandoc.to'))
```

# Supervised machine learning

- Goal is to learn a function $f(\mathbf x)=y$ where $\mathbf
  x\in\mathbb R^p$ is an input/feature vector and $y$ is an
  output/label.
- $\mathbf x=$image of digit/clothing, $y\in\{0,\dots,9\}$ (ten classes).
- $\mathbf x=$vector of word counts in email, $y\in\{1,0\}$ (spam or not).
- This week we will study linear models in depth, and we will focus on
  binary classification, with labels represented by $y\in \{-1,1\}$.
  
---

# Mixture data table

```{python results=TRUE}
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import KFold
import plotnine as p9
# default in inches.
p9.options.figure_size=(4.5,2.5)
# for override in individual plots.
# p9.theme(figure_size=(4.5,2.5))
import numpy as np
np.set_printoptions(linewidth=55)
import pandas as pd
import os
# grid/contouring functions
def make_grid(mat, n_grid = 80):
    nrow, ncol = mat.shape
    assert ncol == 2
    mesh_args = mat.apply(
        lambda x: np.linspace(min(x),max(x), n_grid), axis=0)
    mesh_tup = np.meshgrid(*[mesh_args[x] for x in mesh_args])
    mesh_vectors = [v.flatten() for v in mesh_tup]
    return pd.DataFrame(dict(zip(mesh_args,mesh_vectors)))
# https://scikit-image.org/docs/dev/api/skimage.measure.html#skimage.measure.find_contours
# https://scikit-image.org/docs/dev/auto_examples/edges/plot_contours.html#sphx-glr-auto-examples-edges-plot-contours-py
def contour_paths(three_cols, level):
    from skimage import measure
    uniq_df = three_cols.iloc[:,:2].apply(pd.unique)
    n_grid = uniq_df.shape[0]
    fun_mat = three_cols.iloc[:,2].to_numpy().reshape(
        [n_grid,n_grid]).transpose()
    contours = measure.find_contours(fun_mat, level)
    contour_df_list = []
    half_df = (uniq_df-uniq_df.diff()/2)[1:]
    half_df.index = [x-0.5 for x in half_df.index]
    lookup_df = pd.concat([uniq_df, half_df])
    for contour_i, contour_mat in enumerate(contours):
        one_contour_df = pd.DataFrame(contour_mat)
        one_contour_df.columns = [c+"_i" for c in uniq_df]
        one_contour_df["contour_i"] = contour_i
        for cname in lookup_df:
            iname = cname+"_i"
            contour_col = one_contour_df[iname]
            lookup_col = lookup_df[cname]
            index_df = lookup_col[contour_col].reset_index()
            one_contour_df[cname] = index_df[cname]
        contour_df_list.append(one_contour_df)
    return pd.concat(contour_df_list)

# work-around for rendering plots under windows, which hangs within
# emacs python shell: instead write a PNG file and view in browser.
import webbrowser
on_windows = os.name == "nt"
in_render = r.in_render if 'r' in dir() else False
using_agg = on_windows and not in_render
if using_agg:
    import matplotlib
    matplotlib.use("agg")
def show(g):
    if not using_agg:
        return g
    g.save("tmp.png")
    webbrowser.open('tmp.png')

data_dict = {}

spam_df = pd.read_csv(
    "~/teaching/cs570-spring-2022/data/spam.data",
    header=None, sep=" ")
nrow, ncol = spam_df.shape
label_col_num = ncol-1
col_num_vec = spam_df.columns.to_numpy()
label_vec = spam_df[label_col_num]
feature_mat = spam_df.iloc[:,col_num_vec != label_col_num]
feature_mat.columns = [f"word{col_num}" for col_num in feature_mat]
data_dict["spam"] = (feature_mat, label_vec)

zip_df = pd.read_csv(
    "~/teaching/cs570-spring-2022/data/zip.test.gz",
    sep=" ", header=None)
label_col_num = 0
col_num_vec = zip_df.columns.to_numpy()
all_label_vec = zip_df[label_col_num]
is01 = all_label_vec.isin([0,1])
label_vec = all_label_vec[is01]
feature_mat = zip_df.loc[is01,col_num_vec != label_col_num]
data_dict["zip"] = (feature_mat, label_vec)

mixture_df = pd.read_csv(
    "~/teaching/cs570-spring-2022/data/ESL.mixture.csv")
#mixture_df.query('party == "democratic" & height_in > 70')
label_col_name = "party"
col_name_vec = mixture_df.columns.to_numpy()
party_vec = mixture_df[label_col_name]
party_tuples = [
    ("democratic","blue",0),
    ("republican","red",1)
]
party_colors = {party:color for party,color,number in party_tuples}
party_number_dict = {party:number for party,color,number in party_tuples}
number_party_dict = {number:party for party,color,number in party_tuples}
def number_to_party_vec(v):
    return np.where(v==0, number_party_dict[0], number_party_dict[1])
label_vec = np.where(
    party_vec == "democratic",
    party_number_dict["democratic"],
    party_number_dict["republican"])
feature_mat = mixture_df.loc[:,col_name_vec != label_col_name]
data_dict["mixture"] = (feature_mat, label_vec)
pd.set_option("display.max_columns", 0)
mixture_df

```

---

# Visualize loss as function of real predicted score

```{python}
pred_lim = 5
pred_grid = np.linspace(-pred_lim, pred_lim)
loss_dict = {
    "logistic":lambda f, y: np.log(1+np.exp(-y*f)),
    "zero-one":lambda f, y: np.where(f>0, 1, -1)!=y,
}
loss_df_list = []
for loss_name, loss_fun in loss_dict.items():
    for y in (-1,1):
        loss_df_list.append(pd.DataFrame({
            "loss_name":loss_name,
            "loss_value":loss_fun(pred_grid, y),
            "predicted_score":pred_grid,
            "label":y,
        }))
loss_df = pd.concat(loss_df_list)
gg = p9.ggplot()+\
    p9.facet_grid(". ~ label", labeller="label_both")+\
    p9.scale_x_continuous(breaks=np.arange(-5, 7, 2))+\
    p9.theme_bw()+\
    p9.theme(subplots_adjust={'right': 0.7, "bottom":0.2})+\
    p9.theme(figure_size=(4.5,2))+\
    p9.geom_point(
        p9.aes(
            x="predicted_score",
            y="loss_value",
            color="loss_name",
            ),
        data=loss_df)
show(gg)
```

---

# Loss on probability simplex

```{python}
loss_df["pred_prob1"] = 1/(1+np.exp(-loss_df.predicted_score))
gg = p9.ggplot()+\
    p9.facet_grid(". ~ label", labeller="label_both")+\
    p9.scale_x_continuous(breaks=np.arange(-5, 7, 0.5))+\
    p9.theme_bw()+\
    p9.theme(subplots_adjust={'right': 0.7, "bottom":0.2})+\
    p9.theme(figure_size=(4.5,2))+\
    p9.geom_point(
        p9.aes(
            x="pred_prob1",
            y="loss_value",
            color="loss_name",
            ),
        data=loss_df)
show(gg)
```

# Loss for three classes

```{python}
# equilateral triangle with one vertex at 0,0 another at xmax,0 and
# another at xmax/2,ymax
xmax = 1.0
upper_x = xmax/2.0
ymax = np.sqrt(xmax - upper_x**2)
simplex_grid = make_grid(pd.DataFrame({
    "x":np.linspace(0,xmax),
    "y":np.linspace(0,ymax)
}), n_grid=200)
vertices_mat = np.array([
    [xmax, 0, 1],
    [upper_x, ymax, 1],
    [0,0,1]
])
to_prob_mat = np.linalg.inv(vertices_mat)
simplex_grid_mat = np.column_stack(
    [simplex_grid, np.repeat(1, simplex_grid.shape[0])])
simplex_prob_mat = np.matmul(simplex_grid_mat, to_prob_mat)
keep = simplex_prob_mat.min(axis=1) >= 0
keep_grid = pd.concat([
    pd.DataFrame(simplex_prob_mat), simplex_grid
], axis=1)[keep]
loss_simplex_list = []
loss_max = 5
for label in range(3):
    label_prob = keep_grid[label]
    loss_vec = np.log(1/label_prob)
    loss_only = pd.DataFrame({
        "loss":np.where(loss_vec<loss_max, loss_vec, loss_max),
        "label":label,
    })
    loss_grid = pd.concat([keep_grid.reset_index(), loss_only], axis=1)
    loss_simplex_list.append(loss_grid)
loss_simplex = pd.concat(loss_simplex_list)
gg = p9.ggplot()+\
    p9.facet_grid(". ~ label", labeller="label_both")+\
    p9.geom_tile(
        p9.aes(
            x="x",
            y="y",
            fill="loss",
            ),
        data=loss_simplex)+\
    p9.scale_fill_gradient(
        low="white",
        high="red")+\
    p9.scale_x_continuous(
        name="",
        breaks=[])+\
    p9.scale_y_continuous(
        name="",
        breaks=[])+\
    p9.coord_equal()
show(gg)
```
